fit <- lm(y ~ x)
coeff(fit)
coefficients(fit)
> x <- c(0.8, 0.47, 0.51, 0.73, 0.36, 0.58, 0.57, 0.85, 0.44, 0.42)
> y <- c(1.39, 0.72, 1.55, 0.48, 1.19, -1.59, 1.23, -0.65, 1.49, 0.05)
> fit <- lm(y ~ x)
x <- c(0.8, 0.47, 0.51, 0.73, 0.36, 0.58, 0.57, 0.85, 0.44, 0.42)
y <- c(1.39, 0.72, 1.55, 0.48, 1.19, -1.59, 1.23, -0.65, 1.49, 0.05)
fit <- lm(y ~ x)
coefficients(fit)
data(mtcars)
mtcars
fit <- lm(mpg ~ weight, data = mpf)
fit <- lm(mpg ~ weight, data = mpcars)
data <- data(mtcars)
dB <- data(mtcars)
data <- as.data.frame(data(mtcars))
data(mtcars)
dB <- as.data.frame(mtcars)
data(mtcars)
dB <- as.data.frame(mtcars)
fit <- lm(mpg ~ weight, data = dB)
View(dB)
fit <- lm(mpg ~ wt, data = dB)
coefficients(fit)
.5*.5
1.5*.4
1.5/.4
x <- c(8.58, 10.46, 9.01, 9.64, 8.86)
xn <- (x - mean(x))/sd(x)
xn
x <- c(0.8, 0.47, 0.51, 0.73, 0.36, 0.58, 0.57, 0.85, 0.44, 0.42)
y <- c(1.39, 0.72, 1.55, 0.48, 1.19, -1.59, 1.23, -0.65, 1.49, 0.05)
fit <- lm(y ~ x)
coefficients(fit)
x <- c(0.8, 0.47, 0.51, 0.73, 0.36, 0.58, 0.57, 0.85, 0.44, 0.42)
mean(x)
?lm
x <- c(0.8, 0.47, 0.51, 0.73, 0.36, 0.58, 0.57, 0.85, 0.44, 0.42)
y <- c(1.39, 0.72, 1.55, 0.48, 1.19, -1.59, 1.23, -0.65, 1.49, 0.05)
fit <- lm(y ~ x -1)
coefficients(fit)
corOfYandX <- 0.5
sdYoverX <- 2
beta1 <- corOfYandX*sdYoverX
beta1
?pnorm
pnorm(70, mean = 80, sd = 10)
pnorm(70, mean = 80, sd = 10, lower.tail = FALSE)
qnorm(95, mean = 1100, sd = 75)
qnorm(0.95, mean = 1100, sd = 75)
qnorm(0.95, mean = 1100, sd = 75, lower.tail = FALSE)
qnorm(0.95, mean = 1100, sd = 75, lower.tail = FALSE)
qnorm(0.95)
x <- qnorm(0.95)
(x * (75 / sqrt(100))) + 1100
?pbinom
pbinom(4, 5, 0.5)
pbinom(1, 5, 0.5)
pbinom(5, 5, 0.5)
pbinom(5, 5, 0.5)
pbinom(4, 5, 0.5)
pbinom(4, 5, 0.5, lower.tail = FALSE)
pbinom(3, 5, 0.5, lower.tail = FALSE)
choose(5,4) * 0.5^5 + choose(5,5) * 0.5^5
x <- ((14 - 15) / (10 / sqrt(100)))
y <- ((16 - 15) / (10 / sqrt(100)))
pnorm(y) - pnorm(x)
?runif
runif(10)
mean(runif(100))
mean(runif(1000))
mean(runif(100000000))
mean(runif(1000))
1/sqrt(2)
x <- 1/sqrt(2)
y <- 1 - x
mean(runif(1000, max = x, min = y))
mean(runif(1000, max = x, min = y))
?ppois
ppois(5, 3)
ppois(10, lambda = 5 * 3)
x <- c(0.61, 0.93, 0.83, 0.35, 0.54, 0.16, 0.91, 0.62, 0.62)
y <- c(0.67, 0.84, 0.6, 0.18, 0.85, 0.47, 1.1, 0.65, 0.36)
fit <- lm(x ~ y)
?lm
summary(fit)
x <- c(0.61, 0.93, 0.83, 0.35, 0.54, 0.16, 0.91, 0.62, 0.62)
y <- c(0.67, 0.84, 0.6, 0.18, 0.85, 0.47, 1.1, 0.65, 0.36)
fit <- lm(x ~ y)
summary(fit)
residuals(fit)
sd(residuals(fit))
x <- c(0.61, 0.93, 0.83, 0.35, 0.54, 0.16, 0.91, 0.62, 0.62)
y <- c(0.67, 0.84, 0.6, 0.18, 0.85, 0.47, 1.1, 0.65, 0.36)
fit <- lm(y ~ x)
summary(fit)
dB <- data(mtcars)
data(mtcars)
dB <- as.data.frame(data(mtcars))
?mtcars
mtcars
dB <- as.data.frame(mtcars)
fit <- lm(mpg ~ weight, data = dB)
View(dB)
fit <- lm(mpg ~ wt, data = dB)
mean(dB$wt)
?predict
predict(fit, mean(dB$wt))
predict(fit, mean(dB$wt), interval = "confidence")
dB <- as.data.frame(mtcars)
fit <- lm(mpg ~ wt, data = dB)
predict(fit, mean(dB$wt), interval = "confidence")
predict(fit, as.data.frame(mean(dB$wt)), interval = "confidence")
fit <- lm(mpg ~ wt, data = dB)
predict(fit, newdata = as.data.frame(mean(dB$wt)), interval = "confidence")
predict(fit,data.frame(x=mean(x)), interval="confidence")
dB <- as.data.frame(mtcars)
fit <- lm(mpg ~ wt, data = dB)
predict(fit, newdata = as.data.frame(mean(dB$wt)), interval = "confidence")
predict(fit, newdata = as.data.frame(mean(wt)), interval = "confidence")
predict(fit, 3.21725, interval = "confidence")
dB <- as.data.frame(mtcars)
fit <- lm(mpg ~ wt, data = dB)
x<-mtcars$wt
y<-mtcars$mpg
fit<-lm(y ~ x)
predict(fit,data.frame(x=mean(x)), interval="confidence")
predict(fit, mean(dB$wt), interval = "confidence")
predict(fit, mean(dB$wt), interval = "confidence")
dB <- as.data.frame(mtcars)
fit <- lm(mpg ~ wt, data = dB)
predict(fit, mean(dB$wt), interval = "confidence")
predict(fit, data.frame(mean(dB$wt), interval = "confidence")
predict(fit, data.frame(mean(dB$wt), interval = "confidence"))
predict(fit, data.frame(mean(dB$wt), interval = "confidence"))
predict(fit, data.frame(mean(x = dB$wt), interval = "confidence"))
predict(fit, data.frame(mean(x = mean(x)), interval = "confidence"))
mean <- mean(dB$wt)
predict(fit, mean, interval = "confidence"))
predict(fit, mean, interval = "confidence")
dB <- as.data.frame(mtcars)
fit <- lm(mpg ~ wt, data = dB)
mean <- mean(dB$wt)
predict(fit, mean, interval = "confidence")
dB <- as.data.frame(mtcars)
fit <- lm(mpg ~ wt, data = dB)
mean <- mean(dB$wt)
predict(fit, mean, interval = "confidence")
mean <- data.frame(x = c(mean(dB$wt)))
View(dB)
View(mean)
predict(fit, mean, interval = "confidence")
dB <- as.data.frame(mtcars)
fit <- lm(mpg ~ wt, data = dB)
mean <- data.frame(x = c(mean(dB$wt)))
predict(fit, mean, interval = "confidence")
mean <- data.frame(c(mean(dB$wt)))
predict(fit, mean, interval = "confidence")
x <- mtcars$wt
y <- mtcars$mpg
fit <- lm(y ~ x)
coef <- summary(fit)$coefficients
newdata <- data.frame(x=c(mean(x)))
p1 <- predict(fit, newdata, interval = ("confidence"))
predict(fit, newdata, interval = ("confidence"))
newdata <- data.frame(x=c(mean(x)))
View(newdata)
View(mean)
View(newdata)
View(mean)
predict(fit, newdata, interval = "confidence")
predict(fit, mean, interval = "confidence")
predict(fit, data.fram(mean(dB$wt)), interval = "confidence")
predict(fit, data.frame(mean(dB$wt)), interval = "confidence")
predict(fit, data.frame(mean(dB$wt)), interval = "confidence")
fit <- lm(mpg ~ wt, data = dB)
predict(fit, data.frame(mean(dB$wt)), interval = "confidence")
View(dB)
dB$wt
mean(dB$wt)
data.fram(mean(dB$wt))
x <- data.fram(mean(dB$wt))
x <- data.fram(mean(dB$wt))
x <- data.frame(mean(dB$wt))
x <- data.frame(x = mean(dB$wt))
predict(fit, x, interval = "confidence")
predict(fit, x, interval = "confidence")
predict(fit, x, interval = "confidence")
predict(fit, x, interval = "confidence")
newdata <- data.frame(wt=mean(mtcars$wt))
predict(fit, newdata, interval = ("confidence"))
newdata <- data.frame(wt = mean(mtcars$wt))
predict(fit, newdata, interval = ("confidence"))
dB <- as.data.frame(mtcars)
fit <- lm(mpg ~ wt, data = dB)
newdata <- data.frame(x = mean(mtcars$wt))
predict(fit, newdata, interval = ("confidence"))
newdata <- data.frame(wt = mean(mtcars$wt))
predict(fit, newdata, interval = ("confidence"))
dB <- as.data.frame(mtcars)
fit <- lm(mpg ~ wt, data = dB)
newdata <- data.frame(wt = mean(mtcars$wt))
predict(fit, newdata, interval = ("confidence"))
?mtcars
dB <- as.data.frame(mtcars)
fit <- lm(mpg ~ wt, data = dB)
dB <- as.data.frame(mtcars)
fit <- lm(mpg ~ wt, data = dB)
newdata <- data.frame(wt = 3)
predict(fit, newdata, interval = ("confidence"))
?predict
dB <- as.data.frame(mtcars)
fit <- lm(mpg ~ wt, data = dB)
newdata <- data.frame(wt = 3)
predict(fit, newdata, interval = ("prediction"))
dB <- as.data.frame(mtcars)
fit <- lm(mpg ~ wt*2, data = dB)
dB <- as.data.frame(mtcars)
fit <- lm(mpg ~ wt*2, data = dB)
fit <- lm(mpg ~ (wt*2), data = dB)
fit <- lm(mpg ~ (wt*2), data = dB)
dB <- as.data.frame(mtcars)
fit <- lm(mpg ~ I(wt*2), data = dB)
fit
summary(fit)
fit <- lm(mpg ~ I(wt/2), data = dB)
summary(fit)$coefficients
summary(fit)$coefficients
dB <- as.data.frame(mtcars)
fit <- lm(mpg ~ I(wt/2), data = dB)
summary(fit)$coefficients
sumCoef <- summary(fit)$coefficients
sumCoef[2,1] + c(-1, 1) * qt(.95, df = fit$df) * sumCoef[2, 2]
sumCoef[2,1] + c(-1, 1) * qt(.975, df = fit$df) * sumCoef[2, 2]
dB <- as.data.frame(mtcars)
fit <- lm(mpg ~ I(wt/2), data = dB)
summary(fit)$coefficients
sumCoef <- summary(fit)$coefficients
sumCoef[2,1] + c(-1, 1) * qt(.975, df = fit$df) * sumCoef[2, 2]
?qt
interceptOnly <- lm(mpg ~ 1, data = dB)
interceptAndSlope <- lm(mpg ~ wt, data = dB)
summary(interceptOnly)
anova(interceptOnly)
anova(interceptOnly)[2]
anova(interceptAndSlope)[2] / anova(interceptOnly)[2]
anova(interceptAndSlope)[[2]] / anova(interceptOnly)[[2]]
anova(interceptAndSlope)[[2]]
anova(interceptAndSlope)[[2]]
anova(interceptAndSlope)
anova(interceptAndSlope)[[2, 1]]
anova(interceptAndSlope)[[1, 2]]
anova(interceptAndSlope)[[1, 2]] / anova(interceptOnly)[[2]]
dB <- as.data.frame(mtcars)
interceptOnly <- lm(mpg ~ 1, data = dB)
interceptAndSlope <- lm(mpg ~ wt, data = dB)
anova(interceptAndSlope)[[1, 2]] / anova(interceptOnly)[[2]]
dB <- as.data.frame(mtcars)
interceptOnly <- lm(mpg ~ 1, data = dB)
interceptAndSlope <- lm(mpg ~ wt, data = dB)
anova(interceptAndSlope)
anova(interceptOnly)
anova(interceptAndSlope)[[2, 2]] / anova(interceptOnly)[[2]]
dB <- as.data.frame(mtcars)
interceptOnly <- lm(mpg ~ 1, data = dB)
interceptAndSlope <- lm(mpg ~ wt, data = dB)
anova(interceptAndSlope)[[2, 2]] / anova(interceptOnly)[[2]]
mns = NULL
for (i in 1 : 1000) mns = c(mns, mean(runif(40)))
hist(mns)
hist(runif(1000))
mns = NULL
for (i in 1 : 1000) mns = c(mns, mean(rexp(40, 5)))
hist(mns)
mns = NULL
for (i in 1 : 1000) mns = c(mns, mean(rexp(40, 5)))
hist(mns)
nosim <- 1000
cfunc <- function(x, n) sqrt(n) * (mean(x) - 3.5) / 1.71
dat <- data.frame(
x = c(apply(matrix(sample(1 : 6, nosim * 10, replace = TRUE),
nosim), 1, cfunc, 10),
apply(matrix(sample(1 : 6, nosim * 20, replace = TRUE),
nosim), 1, cfunc, 20),
apply(matrix(sample(1 : 6, nosim * 30, replace = TRUE),
nosim), 1, cfunc, 30)
),
size = factor(rep(c(10, 20, 30), rep(nosim, 3))))
g <- ggplot(dat, aes(x = x, fill = size)) + geom_histogram(alpha = .20, binwidth=.3, colour = "black", aes(y = ..density..))
g <- g + stat_function(fun = dnorm, size = 2)
g + facet_grid(. ~ size)
library(ggplot2)
nosim <- 1000
cfunc <- function(x, n) sqrt(n) * (mean(x) - 3.5) / 1.71
dat <- data.frame(
x = c(apply(matrix(sample(1 : 6, nosim * 10, replace = TRUE),
nosim), 1, cfunc, 10),
apply(matrix(sample(1 : 6, nosim * 20, replace = TRUE),
nosim), 1, cfunc, 20),
apply(matrix(sample(1 : 6, nosim * 30, replace = TRUE),
nosim), 1, cfunc, 30)
),
size = factor(rep(c(10, 20, 30), rep(nosim, 3))))
g <- ggplot(dat, aes(x = x, fill = size)) + geom_histogram(alpha = .20, binwidth=.3, colour = "black", aes(y = ..density..))
g <- g + stat_function(fun = dnorm, size = 2)
g + facet_grid(. ~ size)
nosim <- 1000
cfunc <- function(x, n) 2 * sqrt(n) * (mean(x) - 0.5)
dat <- data.frame(
x = c(apply(matrix(sample(0:1, nosim * 10, replace = TRUE),
nosim), 1, cfunc, 10),
apply(matrix(sample(0:1, nosim * 20, replace = TRUE),
nosim), 1, cfunc, 20),
apply(matrix(sample(0:1, nosim * 30, replace = TRUE),
nosim), 1, cfunc, 30)
),
size = factor(rep(c(10, 20, 30), rep(nosim, 3))))
g <- ggplot(dat, aes(x = x, fill = size)) + geom_histogram(binwidth=.3, colour = "black", aes(y = ..density..))
g <- g + stat_function(fun = dnorm, size = 2)
g + facet_grid(. ~ size)
nosim <- 1000
cfunc <- function(x, n) sqrt(n) * (mean(x) - 3.5) / 1.71
dat <- data.frame(
x = c(apply(matrix(sample(1 : 6, nosim * 10, replace = TRUE),
nosim), 1, cfunc, 10),
apply(matrix(sample(1 : 6, nosim * 20, replace = TRUE),
nosim), 1, cfunc, 20),
apply(matrix(sample(1 : 6, nosim * 30, replace = TRUE),
nosim), 1, cfunc, 30)
),
size = factor(rep(c(10, 20, 30), rep(nosim, 3))))
g <- ggplot(dat, aes(x = x, fill = size)) + geom_histogram(alpha = .20, binwidth=.3, colour = "black", aes(y = ..density..))
g <- g + stat_function(fun = dnorm, size = 2)
g + facet_grid(. ~ size)
View(dat)
nosim <- 1000
cfunc <- function(x, n) sqrt(n) * (mean(x) - 3.5) / 1.71
dat <- data.frame(
x = c(apply(matrix(sample(1 : 6, nosim * 10, replace = TRUE),
nosim), 1, cfunc, 10),
),
size = factor(rep(c(10, 20, 30), rep(nosim, 3))))
g <- ggplot(dat, aes(x = x, fill = size)) + geom_histogram(alpha = .20, binwidth=.3, colour = "black", aes(y = ..density..))
g <- g + stat_function(fun = dnorm, size = 2)
g + facet_grid(. ~ size)
nosim <- 1000
cfunc <- function(x, n) 2 * sqrt(n) * (mean(x) - 0.5)
dat <- data.frame(
x = c(apply(matrix(sample(0:1, nosim * 10, replace = TRUE),
nosim), 1, cfunc, 10),
apply(matrix(sample(0:1, nosim * 20, replace = TRUE),
nosim), 1, cfunc, 20),
apply(matrix(sample(0:1, nosim * 30, replace = TRUE),
nosim), 1, cfunc, 30)
),
size = factor(rep(c(10, 20, 30), rep(nosim, 3))))
View(dat)
size = factor(rep(c(10, 20, 30), rep(nosim, 3))))
View(dat)
g <- ggplot(dat, aes(x = x, fill = size)) + geom_histogram(binwidth=.3, colour = "black", aes(y = ..density..))
g <- g + stat_function(fun = dnorm, size = 2)
g + facet_grid(. ~ size)
mns = NULL
for (i in 1 : 1000) mns = c(mns, mean(runif(40)))
mns
hist(mns)
mns = NULL
for (i in 1 : 1000) mns = c(mns, sd(runif(40)))
hist(mns)
?plot
?ggplot
??ggplot
par(mfrow = c(2, 2))
plot(step_model)
# Set working directory
setwd("~/Documents/GitHub/coursera-datascience-regression-models-project")
# Load up neccessary libraries
library(GGally)
library(data.tables)
# Load in data
dB <- mtcars
# Let's look at the data first to understand structure and basic summary stats
head(dB)
str(dB) # all numerical data
summary(dB)
# Doing a few simple plots to understand relationship between data
# Scatter matrix to understand the relationships between the data
png(filename="pairs.png")
pairs(dB)
dev.off()
# Box plot to understand the relationships between transmission type and mpg
g <- ggplot(dB, aes(factor(am), mpg, fill = factor(am)))
g <- g + geom_boxplot()
g <- g + geom_jitter(position = position_jitter(width = .1, height = 0))
g <- g + scale_colour_discrete(name = "Type")
g <- g + scale_fill_discrete(name = "Type", breaks = c("0", "1"), labels = c("Automatic", "Manual"))
g <- g + scale_x_discrete(breaks = c("0", "1"), labels = c("Automatic", "Manual"))
g <- g + xlab("")
png(filename="boxplot.png")
g
dev.off()
# Doing a t-test (unpaired) to test whether there is a statistically significant different between mpg depending on transmission (one sided test)
g1 <- subset(mtcars, mtcars$am==0)
g2 <- subset(mtcars, mtcars$am==1)
t1 <- t.test(g1$mpg, g2$mpg, alternative="less", paired=F)
t1.summary <- data.frame("p-value" = c(t1$p.value), "CI-Lower" = c(t1$conf[1]), "CI-Upper" = c(t1$conf[2]), row.names = c("Automatic vs. Manual:  "))
round(t1.summary, 3)
# Do a stepwise regression
base_model <- lm(data = dB, mpg ~ am)
summary(base_model)
step_model <- step(lm(data = dB, mpg ~ .), direction = "both", trace = 0)
summary(model)
# Anova test
anova(base_model, step_model)
# Residuals plot
par(mfrow = c(2, 2))
plot(step_model)
?plot
---
title: 'Coursera Data Science Specialisation: Regression Models Course Project'
author: "Danny Chan"
date: "April 2015"
output:
pdf_document: default
html_document: default
---
# Executive Summary
We use the `mtcars` dataset from R to explore two questions, namely:
* “Is an automatic or manual transmission better for MPG”
* "Quantify the MPG difference between automatic and manual transmissions"
We use data visualisation, hypothesis testing and regression analysis to shed light into these two questions. Our anlaysis shows us that:
* Manual transmission is better for MPG;
* Cars with manual transmission have a MPG of 2.9 units higher than the MPG of cars with automatic transmission.
# 1. Exploratory Data Analysis & Statistical Inference
After loading in the dataset `mtcars`, let us first note what variables the dataset contains, and what they measure by using R's handy `?mtcars` help function.
Variable name   | Data Type     | Definition
:-------------- | :-------------| :-------------
mpg             | numeric       | Miles/(US) gallon
cyl             | numeric       | Number of cylinders
disp            | numeric       | Displacement (cu. in.)
hp              | numeric       | Gross horsepower
drat            | numeric       | Rear axle ratio
wt              | numeric       | Weight (lb / 1000)
qsec            | numeric       | 1/4 mile time
vs              | numeric       | V/S
am              | numeric       | Transmission (0 = automatic, 1 = manual)
gear            | numeric       | Number of forward gears
carb            | numeric       | Number of carburetors
Now that we know what the variables mean, let's check out whether the mean of mpg varies by am. We can do a box plot using the very useful `ggplot2` library.
```{r, warning = FALSE, echo = FALSE}
library(ggplot2)
dB <- mtcars
g <- ggplot(dB, aes(factor(am), mpg, fill = factor(am)))
g <- g + geom_boxplot()
g <- g + geom_jitter(position = position_jitter(width = .1, height = 0))
g <- g + scale_colour_discrete(name = "Type")
g <- g + scale_fill_discrete(name = "Type", breaks = c("0", "1"), labels = c("Automatic", "Manual"))
g <- g + scale_x_discrete(breaks = c("0", "1"), labels = c("Automatic", "Manual"))
g <- g + xlab("")
g
```
From the plot, it would seem that cars with manual transmissions are more efficient than cars with automatic transmissions (i.e. manual transmission cars have higher mpg on average).
Let's do a formal statistical inference test, specifically a one-sided unpaired t-test, to test whether the mpg of manual transmission cars are statistically higher than the mpg of automatic transmission cars. We can use R's `t.test` function to do this.
```{r, warning = FALSE}
library(ggplot2)
g1 <- subset(mtcars, mtcars$am==0)
g2 <- subset(mtcars, mtcars$am==1)
t1 <- t.test(g1$mpg, g2$mpg, alternative="less", paired=F)
t1.summary <- data.frame("p-value" = c(t1$p.value), "CI-Lower" = c(t1$conf[1]), "CI-Upper" = c(t1$conf[2]), row.names = c("Automatic vs. Manual:  "))
round(t1.summary, 3)
```
The null hypothesis for the one sided unpaired t-test is that "mpg of manual transmission cars is not different than the mpg of automatic transmission cars", and the alternative hypothesis is that "mpg of manual transmission cars is greater than mpg of authomatic transmission cars". As the p-value for the one sided unpaired t-test is less than 0.05, we can reject the null hypothesis and accept the alternative hypothesis at the 95% significance level.
# 2. Regression Analysis
In the previous section, we found through visualising the data and hypothesis testing that manual transmission cars have migher mpg than automatic transmission cars. In this section, we will use regression analysis to explore this further, and quantify the mpg difference between automatic and manual transmission cars.
## Regression Analysis
After processing the data, we build an two models:
1. An initial model called `base_model` where we regress the variable `am` against `mpg`; and
2. A second model where we initially build a modelwith all the variables as predictors, and perfom stepwise model selection to select significant predictors for the final model which is the best model. This is taken care by the `step` method which runs `lm` multiple times to build multiple regression models and select the best variables from them using both forward selection and backward elimination methods by the `AIC` algorithm.
We then perform an `anova` test to compare the two models.
The code for building the two models are presented below:
```{r, warning = FALSE}
base_model <- lm(data = dB, mpg ~ am)
step_model <- step(lm(data = dB, mpg ~ .), direction = "both", trace = 0)
```
The results of the base model are:
```{r, warning = FALSE}
summary(base_model)
```
The coefficient on `am` tells us that the mpg on manual transmission cars are on average 7.2 units higher than that of the mpg on automatic transmission cars.
The results of the model built using `step` method are:
```{r, warning = FALSE}
summary(step_model)
```
In addition to the `am` variable, the model obtained from the `step` method computations consists of the variables `wt` and `qsec` as additional explanatory variables. The interpretation of the coefficients are:
* `wt`: An increase in the car's weight by 1000lbs decreases `mpg` by 3.9 units (i.e. lighter cars have better `mpg`)
* `qsec`: A 1 second increase in the 1/4 time increases `mpg` by 1.2 units (i.e., cars with quicker `qsec` have better `mpg`)
* `am`: A car with manual transmission increases `mpg` by 2.9 units.
A quick `anova` test shows us that the base model and the model estimated using the `step` are significantly different (o-value is smaller than 0.01, i.e. we reject the null hypothesis that the two models are identical at the 99% significance level) - i.e. the addition of the `wt` and `qsec` improves the model.
```{r, warning = FALSE}
anova(base_model, step_model)
```
## Residuals and Diagnostics
In this section, we shall study the residual plots of our regression model.
```{r, warning = FALSE}
par(mfrow = c(2, 2))
plot(step_model)
```
# Conclusion
Through the use of data visualisation, hypothesis testing and regression analysis, our analysis shows us that:
* Manul transmission is better for MPG;
* Cars with manual transmission have a MPG of 2.9 units higher than the MPG of cars with automatic transmission.
