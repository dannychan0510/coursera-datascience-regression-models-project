predict(fit, x, interval = "confidence")
predict(fit, x, interval = "confidence")
predict(fit, x, interval = "confidence")
predict(fit, x, interval = "confidence")
newdata <- data.frame(wt=mean(mtcars$wt))
predict(fit, newdata, interval = ("confidence"))
newdata <- data.frame(wt = mean(mtcars$wt))
predict(fit, newdata, interval = ("confidence"))
dB <- as.data.frame(mtcars)
fit <- lm(mpg ~ wt, data = dB)
newdata <- data.frame(x = mean(mtcars$wt))
predict(fit, newdata, interval = ("confidence"))
newdata <- data.frame(wt = mean(mtcars$wt))
predict(fit, newdata, interval = ("confidence"))
dB <- as.data.frame(mtcars)
fit <- lm(mpg ~ wt, data = dB)
newdata <- data.frame(wt = mean(mtcars$wt))
predict(fit, newdata, interval = ("confidence"))
?mtcars
dB <- as.data.frame(mtcars)
fit <- lm(mpg ~ wt, data = dB)
dB <- as.data.frame(mtcars)
fit <- lm(mpg ~ wt, data = dB)
newdata <- data.frame(wt = 3)
predict(fit, newdata, interval = ("confidence"))
?predict
dB <- as.data.frame(mtcars)
fit <- lm(mpg ~ wt, data = dB)
newdata <- data.frame(wt = 3)
predict(fit, newdata, interval = ("prediction"))
dB <- as.data.frame(mtcars)
fit <- lm(mpg ~ wt*2, data = dB)
dB <- as.data.frame(mtcars)
fit <- lm(mpg ~ wt*2, data = dB)
fit <- lm(mpg ~ (wt*2), data = dB)
fit <- lm(mpg ~ (wt*2), data = dB)
dB <- as.data.frame(mtcars)
fit <- lm(mpg ~ I(wt*2), data = dB)
fit
summary(fit)
fit <- lm(mpg ~ I(wt/2), data = dB)
summary(fit)$coefficients
summary(fit)$coefficients
dB <- as.data.frame(mtcars)
fit <- lm(mpg ~ I(wt/2), data = dB)
summary(fit)$coefficients
sumCoef <- summary(fit)$coefficients
sumCoef[2,1] + c(-1, 1) * qt(.95, df = fit$df) * sumCoef[2, 2]
sumCoef[2,1] + c(-1, 1) * qt(.975, df = fit$df) * sumCoef[2, 2]
dB <- as.data.frame(mtcars)
fit <- lm(mpg ~ I(wt/2), data = dB)
summary(fit)$coefficients
sumCoef <- summary(fit)$coefficients
sumCoef[2,1] + c(-1, 1) * qt(.975, df = fit$df) * sumCoef[2, 2]
?qt
interceptOnly <- lm(mpg ~ 1, data = dB)
interceptAndSlope <- lm(mpg ~ wt, data = dB)
summary(interceptOnly)
anova(interceptOnly)
anova(interceptOnly)[2]
anova(interceptAndSlope)[2] / anova(interceptOnly)[2]
anova(interceptAndSlope)[[2]] / anova(interceptOnly)[[2]]
anova(interceptAndSlope)[[2]]
anova(interceptAndSlope)[[2]]
anova(interceptAndSlope)
anova(interceptAndSlope)[[2, 1]]
anova(interceptAndSlope)[[1, 2]]
anova(interceptAndSlope)[[1, 2]] / anova(interceptOnly)[[2]]
dB <- as.data.frame(mtcars)
interceptOnly <- lm(mpg ~ 1, data = dB)
interceptAndSlope <- lm(mpg ~ wt, data = dB)
anova(interceptAndSlope)[[1, 2]] / anova(interceptOnly)[[2]]
dB <- as.data.frame(mtcars)
interceptOnly <- lm(mpg ~ 1, data = dB)
interceptAndSlope <- lm(mpg ~ wt, data = dB)
anova(interceptAndSlope)
anova(interceptOnly)
anova(interceptAndSlope)[[2, 2]] / anova(interceptOnly)[[2]]
dB <- as.data.frame(mtcars)
interceptOnly <- lm(mpg ~ 1, data = dB)
interceptAndSlope <- lm(mpg ~ wt, data = dB)
anova(interceptAndSlope)[[2, 2]] / anova(interceptOnly)[[2]]
mns = NULL
for (i in 1 : 1000) mns = c(mns, mean(runif(40)))
hist(mns)
hist(runif(1000))
mns = NULL
for (i in 1 : 1000) mns = c(mns, mean(rexp(40, 5)))
hist(mns)
mns = NULL
for (i in 1 : 1000) mns = c(mns, mean(rexp(40, 5)))
hist(mns)
nosim <- 1000
cfunc <- function(x, n) sqrt(n) * (mean(x) - 3.5) / 1.71
dat <- data.frame(
x = c(apply(matrix(sample(1 : 6, nosim * 10, replace = TRUE),
nosim), 1, cfunc, 10),
apply(matrix(sample(1 : 6, nosim * 20, replace = TRUE),
nosim), 1, cfunc, 20),
apply(matrix(sample(1 : 6, nosim * 30, replace = TRUE),
nosim), 1, cfunc, 30)
),
size = factor(rep(c(10, 20, 30), rep(nosim, 3))))
g <- ggplot(dat, aes(x = x, fill = size)) + geom_histogram(alpha = .20, binwidth=.3, colour = "black", aes(y = ..density..))
g <- g + stat_function(fun = dnorm, size = 2)
g + facet_grid(. ~ size)
library(ggplot2)
nosim <- 1000
cfunc <- function(x, n) sqrt(n) * (mean(x) - 3.5) / 1.71
dat <- data.frame(
x = c(apply(matrix(sample(1 : 6, nosim * 10, replace = TRUE),
nosim), 1, cfunc, 10),
apply(matrix(sample(1 : 6, nosim * 20, replace = TRUE),
nosim), 1, cfunc, 20),
apply(matrix(sample(1 : 6, nosim * 30, replace = TRUE),
nosim), 1, cfunc, 30)
),
size = factor(rep(c(10, 20, 30), rep(nosim, 3))))
g <- ggplot(dat, aes(x = x, fill = size)) + geom_histogram(alpha = .20, binwidth=.3, colour = "black", aes(y = ..density..))
g <- g + stat_function(fun = dnorm, size = 2)
g + facet_grid(. ~ size)
nosim <- 1000
cfunc <- function(x, n) 2 * sqrt(n) * (mean(x) - 0.5)
dat <- data.frame(
x = c(apply(matrix(sample(0:1, nosim * 10, replace = TRUE),
nosim), 1, cfunc, 10),
apply(matrix(sample(0:1, nosim * 20, replace = TRUE),
nosim), 1, cfunc, 20),
apply(matrix(sample(0:1, nosim * 30, replace = TRUE),
nosim), 1, cfunc, 30)
),
size = factor(rep(c(10, 20, 30), rep(nosim, 3))))
g <- ggplot(dat, aes(x = x, fill = size)) + geom_histogram(binwidth=.3, colour = "black", aes(y = ..density..))
g <- g + stat_function(fun = dnorm, size = 2)
g + facet_grid(. ~ size)
nosim <- 1000
cfunc <- function(x, n) sqrt(n) * (mean(x) - 3.5) / 1.71
dat <- data.frame(
x = c(apply(matrix(sample(1 : 6, nosim * 10, replace = TRUE),
nosim), 1, cfunc, 10),
apply(matrix(sample(1 : 6, nosim * 20, replace = TRUE),
nosim), 1, cfunc, 20),
apply(matrix(sample(1 : 6, nosim * 30, replace = TRUE),
nosim), 1, cfunc, 30)
),
size = factor(rep(c(10, 20, 30), rep(nosim, 3))))
g <- ggplot(dat, aes(x = x, fill = size)) + geom_histogram(alpha = .20, binwidth=.3, colour = "black", aes(y = ..density..))
g <- g + stat_function(fun = dnorm, size = 2)
g + facet_grid(. ~ size)
View(dat)
nosim <- 1000
cfunc <- function(x, n) sqrt(n) * (mean(x) - 3.5) / 1.71
dat <- data.frame(
x = c(apply(matrix(sample(1 : 6, nosim * 10, replace = TRUE),
nosim), 1, cfunc, 10),
),
size = factor(rep(c(10, 20, 30), rep(nosim, 3))))
g <- ggplot(dat, aes(x = x, fill = size)) + geom_histogram(alpha = .20, binwidth=.3, colour = "black", aes(y = ..density..))
g <- g + stat_function(fun = dnorm, size = 2)
g + facet_grid(. ~ size)
nosim <- 1000
cfunc <- function(x, n) 2 * sqrt(n) * (mean(x) - 0.5)
dat <- data.frame(
x = c(apply(matrix(sample(0:1, nosim * 10, replace = TRUE),
nosim), 1, cfunc, 10),
apply(matrix(sample(0:1, nosim * 20, replace = TRUE),
nosim), 1, cfunc, 20),
apply(matrix(sample(0:1, nosim * 30, replace = TRUE),
nosim), 1, cfunc, 30)
),
size = factor(rep(c(10, 20, 30), rep(nosim, 3))))
View(dat)
size = factor(rep(c(10, 20, 30), rep(nosim, 3))))
View(dat)
g <- ggplot(dat, aes(x = x, fill = size)) + geom_histogram(binwidth=.3, colour = "black", aes(y = ..density..))
g <- g + stat_function(fun = dnorm, size = 2)
g + facet_grid(. ~ size)
mns = NULL
for (i in 1 : 1000) mns = c(mns, mean(runif(40)))
mns
hist(mns)
mns = NULL
for (i in 1 : 1000) mns = c(mns, sd(runif(40)))
hist(mns)
library(GGally)
dB <- mtcars
# Let's look at the data first
head(dB)
str(dB) # all numerical data
summary(dB)
ggpairs(dB)
ggpairs(dB, axisLabels = None)
ggpairs(dB, axisLabels = "None")
ggpairs(dB, axisLabels = "None") +   theme(line = element_blank(),
text = element_blank(),
line = element_blank(),
title = element_blank())
ggpairs(dB, axisLabels = "None") +   theme(line = element_blank(), text = element_blank(), line = element_blank(), title = element_blank())
plotmatrix(dB, axisLabels = "None")
library(ggplot2)
plotmatrix(dB, axisLabels = "None")
plotmatrix(dB)
ggpairs(iris, alpha = 0.4)
ggpairs(mtcars, alpha = 0.4)
ggpairs(mtcars, alpha = 0.4, axisLabels = "none")
ggpairs(mtcars, alpha = 0.4, axisLabels = "none", colour = "blue")
ggpairs(mtcars, alpha = 0.4, axisLabels = "none", aes(colour = "blue")
ggpairs(mtcars, alpha = 0.4, axisLabels = "none", aes(colour = "blue"))
ggpairs(mtcars, alpha = 0.4, axisLabels = "none", aes(colour = "blue"))
ggpairs(mtcars, alpha = 0.4, axisLabels = "none") + geom_point(colour = "blue")
ggpairs(mtcars, alpha = 0.4, axisLabels = "none")
pairs(dB)
?pairs
pairs(dB, alpha = 0.4)
?pairs
boxplot(mpg ~ am, data = dB, xlab = "Transmission (0 = automatic, 1 = manual)")
ggplot(mtcars, aes(factor(am), mpg)) + geom_boxplot()
ggplot(mtcars, aes(factor(am), mpg)) + geom_boxplot() # Box-plot to understand how mpg varies with am
?mtcars
ggplot(mtcars, aes(factor(am), mpg)) + geom_boxplot() # Box-plot to understand how mpg varies with am - seems like mpg is higher for manual transmission cars
pairs(dB) # Scatter matrix to understand the relationships between the data
?pairs
png(filename="pairs.png")
pairs(dB) # Scatter matrix to understand the relationships between the data
dev.off()
setwd("~/Documents/GitHub/coursera-datascience-regression-models-project")
png(filename="pairs.png")
pairs(dB) # Scatter matrix to understand the relationships between the data
dev.off()
png(filename="boxplot.png")
ggplot(mtcars, aes(factor(am), mpg)) + geom_boxplot() # Box-plot to understand how mpg varies with am - seems like mpg is higher for manual transmission cars
dev.off()
head(dB)
lm(mpg ~ am, data = dB)
lm(mpg ~ am + cyl, data = dB)
lm(mpg ~ am + cyl + disp + hp + drat + wt + qsec + vs + gear + carb, data = dB)
fit <- lm(mpg ~ am + cyl + disp + hp + drat + wt + qsec + vs + gear + carb, data = dB)
p.values(fit)
summary(fit)
?mtcars
ggplot(mtcars, aes(factor(am), mpg)) + geom_boxplot() # Box-plot to understand how mpg varies with am - seems like mpg is higher for manual transmission cars
g = ggplot(dB, aes(factor(am), mpg, fill=factor(am)))
g = g + geom_boxplot()
g = g + geom_jitter(position=position_jitter(width=.1, height=0))
g = g + scale_colour_discrete(name = "Type")
g = g + scale_fill_discrete(name="Type", breaks=c("0", "1"),
labels=c("Automatic", "Manual"))
g = g + scale_x_discrete(breaks=c("0", "1"), labels=c("Automatic", "Manual"))
g = g + xlab("")
png(filename="boxplot.png")
g
dev.off()
g
t <- t.test(mpg ~ am, data = dB)
t1 <- t.test(mpg ~ am, data = dB)
t1.summary <- data.frame("p-value" = c(t1$p.value), "CI-Lower" = c(t1$conf[1]), "CI-Upper" = c(t1$conf[2]), row.names = c("Automatic vs. Manual:  "))
round(t1.summary, 4)
# Set working directory
setwd("~/Documents/GitHub/coursera-datascience-regression-models-project")
# Load up neccessary libraries
library(GGally)
library(data.tables)
# Load in data
dB <- mtcars
# Let's look at the data first to understand structure and basic summary stats
head(dB)
str(dB) # all numerical data
summary(dB)
# Doing a few simple plots to understand relationship between data
# Scatter matrix to understand the relationships between the data
png(filename="pairs.png")
pairs(dB)
dev.off()
# Box plot to understand the relationships between transmission type and mpg
g <- ggplot(dB, aes(factor(am), mpg, fill = factor(am)))
g <- g + geom_boxplot()
g <- g + geom_jitter(position = position_jitter(width = .1, height = 0))
g <- g + scale_colour_discrete(name = "Type")
g <- g + scale_fill_discrete(name = "Type", breaks = c("0", "1"), labels = c("Automatic", "Manual"))
g <- g + scale_x_discrete(breaks = c("0", "1"), labels = c("Automatic", "Manual"))
g <- g + xlab("")
png(filename="boxplot.png")
g
dev.off()
# Doing a t-test (unpaired) to test whether there is a statistically significant different between mpg depending on transmission
t1 <- t.test(mpg ~ am, data = dB)
t1.summary <- data.frame("p-value" = c(t1$p.value), "CI-Lower" = c(t1$conf[1]), "CI-Upper" = c(t1$conf[2]), row.names = c("Automatic vs. Manual:  "))
round(t1.summary, 4)
?step
t1 <- t.test(mpg ~ am, data = dB)
t1.summary <- data.frame("p-value" = c(t1$p.value), "CI-Lower" = c(t1$conf[1]), "CI-Upper" = c(t1$conf[2]), row.names = c("Automatic vs. Manual:  "))
round(t1.summary, 4)
t1 <- t.test(mpg ~ am, data = dB, alternative = "greater")
t1.summary <- data.frame("p-value" = c(t1$p.value), "CI-Lower" = c(t1$conf[1]), "CI-Upper" = c(t1$conf[2]), row.names = c("Automatic vs. Manual:  "))
round(t1.summary, 4)
t1 <- t.test(mpg ~ am, data = dB, alternative = "greater")
t1.summary <- data.frame("p-value" = c(t1$p.value), "CI-Lower" = c(t1$conf[1]), "CI-Upper" = c(t1$conf[2]), row.names = c("Automatic vs. Manual:  "))
round(t1.summary, 4)
t1 <- t.test(mpg ~ am, data = dB, alternative = "greater", paired = F)
t1.summary <- data.frame("p-value" = c(t1$p.value), "CI-Lower" = c(t1$conf[1]), "CI-Upper" = c(t1$conf[2]), row.names = c("Automatic vs. Manual:  "))
round(t1.summary, 4)
t1 <- t.test(mpg ~ am, data = dB, paired = F)
t1.summary <- data.frame("p-value" = c(t1$p.value), "CI-Lower" = c(t1$conf[1]), "CI-Upper" = c(t1$conf[2]), row.names = c("Automatic vs. Manual:  "))
round(t1.summary, 4)
g1 <- subset(mtcars, mtcars$am==0)
g2 <- subset(mtcars, mtcars$am==1)
t1 <- t.test(g1, g2, alternative="greater", paired=F)
t1.summary <- data.frame("p-value" = c(t1$p.value), "CI-Lower" = c(t1$conf[1]), "CI-Upper" = c(t1$conf[2]), row.names = c("Automatic vs. Manual:  "))
round(t1.summary, 4)
t1 <- t.test(g1$mpg, g2$mpg, alternative="greater", paired=F)
t1.summary <- data.frame("p-value" = c(t1$p.value), "CI-Lower" = c(t1$conf[1]), "CI-Upper" = c(t1$conf[2]), row.names = c("Automatic vs. Manual:  "))
round(t1.summary, 4)
?t.test
t1 <- t.test(g1$mpg, g2$mpg, alternative="less", paired=F)
t1.summary <- data.frame("p-value" = c(t1$p.value), "CI-Lower" = c(t1$conf[1]), "CI-Upper" = c(t1$conf[2]), row.names = c("Automatic vs. Manual:  "))
round(t1.summary, 4)
t1.summary <- data.frame("p-value" = c(t1$p.value), "CI-Lower" = c(t1$conf[1]), "CI-Upper" = c(t1$conf[2]), row.names = c("Automatic vs. Manual:  "))
round(t1.summary, 3)
round(t1.summary, 4)
round(t1.summary, 3)
g1 <- subset(mtcars, mtcars$am==0)
g2 <- subset(mtcars, mtcars$am==1)
t1 <- t.test(g1$mpg, g2$mpg, alternative="less", paired=F)
t1.summary <- data.frame("p-value" = c(t1$p.value), "CI-Lower" = c(t1$conf[1]), "CI-Upper" = c(t1$conf[2]), row.names = c("Automatic vs. Manual:  "))
round(t1.summary, 3)
?step
s_model <- step(lm(data = mtcars, mpg~.), trace = 0)
summary(s_model)
s_model <- step(lm(data = mtcars, mpg~.), direction = "both")
summary(s_model)
s_model <- step(lm(data = mtcars, mpg ~ .), direction = "both", trace = 0)
summary(s_model)
s_model <- step(lm(data = dB, mpg ~ .), direction = "both", trace = 0)
summary(s_model)
initialmodel <- lm(mpg ~ ., data = mtcars)
bestmodel <- step(initialmodel, direction = "both")
summary(bestmodel)
fit <- lm(mpg ~ am, data = dB)
summary(fit)
model <- step(lm(data = dB, mpg ~ .), direction = both, trace = 0)
summary(mode)
model <- step(lm(data = dB, mpg ~ .), direction = both, trace = 0)
model <- step(lm(data = dB, mpg ~ .), direction = "both", trace = 0)
model <- step(lm(data = dB, mpg ~ .), direction = "both", trace = 0)
summary(model)
dB$cyl <- factor(dB$cyl)
dB$vs <- factor(dB$vs)
dB$gear <- factor(dB$gear)
dB$carb <- factor(dB$carb)
dB$am <- factor(dB$am,labels=c('Automatic','Manual'))
str(dB)
model <- step(lm(data = dB, mpg ~ .), direction = "both", trace = 0)
summary(model)
summary(base_model)
base_model <-lm(data = dB, mpg ~ am.)
summary(base_model)
base_model <- lm(data = dB, mpg ~ am.)
base_model <- lm(data = dB, mpg ~ am)
summary(base_model)
---
title: 'Coursera Data Science Specialisation: Regression Models Course Project'
author: "Danny Chan"
date: "April 2015"
output:
html_document: default
---
# Executive Summary
# Context
Motor Trend, a magazine about the automobile industry are interested in exploring the relationship between a set of variables and miles per gallon (MPG) (outcome). They are particularly interested in the following two questions:
* “Is an automatic or manual transmission better for MPG”
* "Quantify the MPG difference between automatic and manual transmissions"
This report will explore these two questions by conducting:
1. Exploratory Data Analysis & Statistical Inference; and
2. Regression Analysis.
# 1. Exploratory Data Analysis & Statistical Inference
After loading in the dataset `mtcars`, let us first note what variables the dataset contains, and what they measure by using R's handy `?mtcars` help function.
Variable name   | Data Type     | Definition
:-------------- | :-------------| :-------------
mpg             | numeric       | Miles/(US) gallon
cyl             | numeric       | Number of cylinders
disp            | numeric       | Displacement (cu. in.)
hp              | numeric       | Gross horsepower
drat            | numeric       | Rear axle ratio
wt              | numeric       | Weight (lb / 1000)
qsec            | numeric       | 1/4 mile time
vs              | numeric       | V/S
am              | numeric       | Transmission (0 = automatic, 1 = manual)
gear            | numeric       | Number of forward gears
carb            | numeric       | Number of carburetors
Now that we know what the variables mean, let's check out whether the mean of mpg varies by am. We can do a box plot using the very useful `ggplot2` library.
```{r, warning = FALSE}
library(ggplot2)
dB <- mtcars
g <- ggplot(dB, aes(factor(am), mpg, fill = factor(am)))
g <- g + geom_boxplot()
g <- g + geom_jitter(position = position_jitter(width = .1, height = 0))
g <- g + scale_colour_discrete(name = "Type")
g <- g + scale_fill_discrete(name = "Type", breaks = c("0", "1"), labels = c("Automatic", "Manual"))
g <- g + scale_x_discrete(breaks = c("0", "1"), labels = c("Automatic", "Manual"))
g <- g + xlab("")
g
```
From the plot, it would seem that cars with manual transmissions are more efficient than cars with automatic transmissions (i.e. manual transmission cars have higher mpg on average).
Let's do a formal statistical inference test, specifically a one-sided unpaired t-test, to test whether the mpg of manual transmission cars are statistically higher than the mpg of automatic transmission cars. We can use R's `t.test` function to do this.
```{r, warning = FALSE}
library(ggplot2)
g1 <- subset(mtcars, mtcars$am==0)
g2 <- subset(mtcars, mtcars$am==1)
t1 <- t.test(g1$mpg, g2$mpg, alternative="less", paired=F)
t1.summary <- data.frame("p-value" = c(t1$p.value), "CI-Lower" = c(t1$conf[1]), "CI-Upper" = c(t1$conf[2]), row.names = c("Automatic vs. Manual:  "))
round(t1.summary, 3)
```
The null hypothesis for the one sided unpaired t-test is that "mpg of manual transmission cars is not different than the mpg of automatic transmission cars", and the alternative hypothesis is that "mpg of manual transmission cars is greater than mpg of authomatic transmission cars". As the p-value for the one sided unpaired t-test is less than 0.05, we can reject the null hypothesis and accept the alternative hypothesis at the 95% significance level.
# 2. Regression Analysis
In the previous section, we found through visualising the data and hypothesis testing that manual transmission cars have migher mpg than automatic transmission cars. In this section, we will use regression analysis to explore this further, and quantify the mpg difference between automatic and manual transmission cars.
## Data Processing
To make the regression analysis possible, some data processing first needs to be done. Specifically, the `cyl`, `vs`, `gear`, `carb` and `am` variables need to be converted from numerical to factor.
```{r, warning = FALSE}
dB$cyl <- factor(dB$cyl)
dB$vs <- factor(dB$vs)
dB$gear <- factor(dB$gear)
dB$carb <- factor(dB$carb)
dB$am <- factor(dB$am,labels = c('Automatic','Manual'))
```
## Regression Analysis
After processing the data, we build an two models:
1. An initial model called `base_model` where we regress the variable `am` against `mpg`; and
2. A second model where we initially build a modelwith all the variables as predictors, and perfom stepwise model selection to select significant predictors for the final model which is the best model. This is taken care by the `step` method which runs `lm` multiple times to build multiple regression models and select the best variables from them using both forward selection and backward elimination methods by the `AIC` algorithm.
We then perform an `anova` test to compare the two models.
The code for building the two models are presented below:
```{r, warning = FALSE, echo = FALSE}
base_model <- lm(data = dB, mpg ~ am)
step_model <- step(lm(data = dB, mpg ~ .), direction = "both", trace = 0)
```
---
title: 'Coursera Data Science Specialisation: Regression Models Course Project'
author: "Danny Chan"
date: "April 2015"
output:
html_document: default
---
# Executive Summary
# Context
Motor Trend, a magazine about the automobile industry are interested in exploring the relationship between a set of variables and miles per gallon (MPG) (outcome). They are particularly interested in the following two questions:
* “Is an automatic or manual transmission better for MPG”
* "Quantify the MPG difference between automatic and manual transmissions"
This report will explore these two questions by conducting:
1. Exploratory Data Analysis & Statistical Inference; and
2. Regression Analysis.
# 1. Exploratory Data Analysis & Statistical Inference
After loading in the dataset `mtcars`, let us first note what variables the dataset contains, and what they measure by using R's handy `?mtcars` help function.
Variable name   | Data Type     | Definition
:-------------- | :-------------| :-------------
mpg             | numeric       | Miles/(US) gallon
cyl             | numeric       | Number of cylinders
disp            | numeric       | Displacement (cu. in.)
hp              | numeric       | Gross horsepower
drat            | numeric       | Rear axle ratio
wt              | numeric       | Weight (lb / 1000)
qsec            | numeric       | 1/4 mile time
vs              | numeric       | V/S
am              | numeric       | Transmission (0 = automatic, 1 = manual)
gear            | numeric       | Number of forward gears
carb            | numeric       | Number of carburetors
Now that we know what the variables mean, let's check out whether the mean of mpg varies by am. We can do a box plot using the very useful `ggplot2` library.
```{r, warning = FALSE}
library(ggplot2)
dB <- mtcars
g <- ggplot(dB, aes(factor(am), mpg, fill = factor(am)))
g <- g + geom_boxplot()
g <- g + geom_jitter(position = position_jitter(width = .1, height = 0))
g <- g + scale_colour_discrete(name = "Type")
g <- g + scale_fill_discrete(name = "Type", breaks = c("0", "1"), labels = c("Automatic", "Manual"))
g <- g + scale_x_discrete(breaks = c("0", "1"), labels = c("Automatic", "Manual"))
g <- g + xlab("")
g
```
From the plot, it would seem that cars with manual transmissions are more efficient than cars with automatic transmissions (i.e. manual transmission cars have higher mpg on average).
Let's do a formal statistical inference test, specifically a one-sided unpaired t-test, to test whether the mpg of manual transmission cars are statistically higher than the mpg of automatic transmission cars. We can use R's `t.test` function to do this.
```{r, warning = FALSE}
library(ggplot2)
g1 <- subset(mtcars, mtcars$am==0)
g2 <- subset(mtcars, mtcars$am==1)
t1 <- t.test(g1$mpg, g2$mpg, alternative="less", paired=F)
t1.summary <- data.frame("p-value" = c(t1$p.value), "CI-Lower" = c(t1$conf[1]), "CI-Upper" = c(t1$conf[2]), row.names = c("Automatic vs. Manual:  "))
round(t1.summary, 3)
```
The null hypothesis for the one sided unpaired t-test is that "mpg of manual transmission cars is not different than the mpg of automatic transmission cars", and the alternative hypothesis is that "mpg of manual transmission cars is greater than mpg of authomatic transmission cars". As the p-value for the one sided unpaired t-test is less than 0.05, we can reject the null hypothesis and accept the alternative hypothesis at the 95% significance level.
# 2. Regression Analysis
In the previous section, we found through visualising the data and hypothesis testing that manual transmission cars have migher mpg than automatic transmission cars. In this section, we will use regression analysis to explore this further, and quantify the mpg difference between automatic and manual transmission cars.
## Data Processing
To make the regression analysis possible, some data processing first needs to be done. Specifically, the `cyl`, `vs`, `gear`, `carb` and `am` variables need to be converted from numerical to factor.
```{r, warning = FALSE}
dB$cyl <- factor(dB$cyl)
dB$vs <- factor(dB$vs)
dB$gear <- factor(dB$gear)
dB$carb <- factor(dB$carb)
dB$am <- factor(dB$am,labels = c('Automatic','Manual'))
```
## Regression Analysis
After processing the data, we build an two models:
1. An initial model called `base_model` where we regress the variable `am` against `mpg`; and
2. A second model where we initially build a modelwith all the variables as predictors, and perfom stepwise model selection to select significant predictors for the final model which is the best model. This is taken care by the `step` method which runs `lm` multiple times to build multiple regression models and select the best variables from them using both forward selection and backward elimination methods by the `AIC` algorithm.
We then perform an `anova` test to compare the two models.
The code for building the two models are presented below:
```{r, warning = FALSE, echo = FALSE}
base_model <- lm(data = dB, mpg ~ am)
step_model <- step(lm(data = dB, mpg ~ .), direction = "both", trace = 0)
```
head(dB)
?mtcars
anova(base_model, step_model)
